---
title: "Simulação de Eventos Discretos \nAtividade III"
author: "Daniel dos Santos"
date: "`r format(Sys.Date(), '%d de %B de %Y.')`"
output: pdf_document

---

```{r include=FALSE}
library(ggplot2, quietly = TRUE)
```

# Funções auxiliares

`expr` gera uma exponencial de parâmetro $\lambda$:
$$X\sim Exp(\lambda)$$

```{r}
expr <- function(lambda){
  u <- runif(1)
  return(-1*log(u)/lambda)
}
```

`exprn` gera uma sequência de v.a.'s com distribuição exponencial de parâmetro $\lambda$:
$$(X_1,X_2,\dots,X_n)\sim Exp(\lambda)$$
```{r}
exprn <- function(n,lambda){
  exp <- NULL
  for(i in 1:n){
    exp[i] <- expr(lambda)
  }
  return(exp)
}
```

# Questão 1
Sendo, $(X_1,X_2,\dots, X_5)\sim Exp(1)$ i.i.d.'s.
$$\theta=\mathbb{P}\left(\sum_{i=1}^{5}iX_i\ge21.6\right)$$

## a) Não usaremos nenhum método de  redução de variância.

Nesse primeiro caso não utilizaremos nenhum método de redução de variância para estimar o valor de $\theta$.
Logo, definimos a indicadora:
$$I=\begin{cases} 1, & \mbox{se } \displaystyle\sum_{i=1}^5 iX_{i}\geqslant21.6\\ 0, & \mbox{c.c.}\end{cases}$$  
Dessa forma temos o seguinte resultado:
$$\theta=\mathbb{E}[I]=1\cdot\mathbb{P}\left( \displaystyle\sum_{i=1}^5 iX_{i}\geqslant21.6 \right) + 0 \cdot \left (\displaystyle\sum_{i=1}^5 iX_{i}<21.6\right) = \mathbb{P}\left( \displaystyle\sum_{i=1}^5 iX_{i}\geqslant21.6 \right)$$

```{r}
q1_a <- function(n){
  prob <- NULL ;  temp <- NULL
  for(j in 1:n){
    for(i in 1:n) temp[i] <- ifelse(sum(1:5*exprn(5, 1)) >= 21.6, 1, 0)
    prob[j] <- mean(temp)
  }
  return(mean(prob))
}
```
```{r echo=FALSE}
a <- q1_a(100) ; a
```

O valor estimado para $\theta$ nesse caso foi de `r a`.

## b) Variáveis antagônicas
Sejam:
$$X_1 = h(U_1,U_2, \dots, U_m)$$
$$X_2 = h(1-U_1,1-U_2, \dots, 1-U_m)$$
\begin{center}
Onde,
\end{center}
$$Ui \sim U(0,1) \\ i = 1,2,\dots,m$$
Perceba que, $X_1$ e $X_2$ são dependentes e são negativamente correlacionados, dessa forma:
$$Var\left(\frac{X_1+X_2}{2}\right) = \frac{1}{4}Var(X_1)+[Var(X_2)+2Cov(X_1,X_2)]$$
É possível provar que a variância pelo método das variáveis antagônicas será menor do que se não utilizarmos nenhum método.

```{r}
q1_b <- function(n){
  media <- NULL ; prob <- NULL
  for(j in 1:n){
    for(i in 1:n){
      u <- runif(5)
      r1 <- ifelse(sum(1:5*(-log(u))) >= 21.6 , 1, 0)
      r2 <- ifelse(sum(1:5*(-log(1-u))) >= 21.6, 1, 0)
      media[i] <- mean(c(r1, r2))
   }
   prob[j] <- mean(media) 
  }
  return(mean(prob))
}
```
```{r echo=FALSE}
b <- q1_b(100) ; b
```

O valor estimado para $\theta$ por esse método foi de `r b`.

## c) Variável controle
Definindo a variável controle: $Z=\displaystyle\sum_{i=1}^5 iX_{i} \Rightarrow \mathbb{E}[Z]=15$ e $Var[Z]=55$.
Simulando $Cov(Y,Z)$, onde $Y=I$

```{r}
q1_c <- function(n){
  prob <- NULL ; y <- NULL ; z <- NULL
  for(j in 1:n){
    for(i in 1:n){
      y[i] <- ifelse(sum(1:5*(-log(runif(5)))) >= 21.6 , 1, 0)
      z[i] <- sum(1:5*(-log(runif(5))))
    }
    covariance <- cov(y, z)
    prob[j] <- mean(y)-(covariance/55)*(mean(z)-15)
  }
  return(mean(prob))
}
```

```{r echo=FALSE}
c <- q1_c(100) ; c
```


## d) Qual método reduziu mais a variância?

Fiz uma análise descritiva para verificar qual método reduziu mais a variância. Através do gráfico abaixo podemos observar que o método das [\underline{variáveis antagônicas}](#b-variaveis-antagonicas) obteve uma variância menor do que o método da [\underline{variávei controle}](#c-variavel-controle).

```{r echo=FALSE}
# Ggplot2 library
antagonica <- NULL
for(i in 1:100){
  antagonica[i] <- q1_b(100)
}

controle <- NULL
for(i in 1:100){
  controle[i] <- q1_c(100)
}
 
# Data 
names=c(rep("Antagônica", 100) , rep("Controle", 100))
value=c(antagonica,controle)
data=data.frame(names,value)
 
#Graph
qplot(x=names , y=value , data=data , geom=c("boxplot","jitter") , fill=names, xlab = 'Método', ylab = 'Estimação')
```
Foi o usado o pacote `ggplot2` para gerar esses gráficos.